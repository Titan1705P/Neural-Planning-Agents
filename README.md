## Abstract

Reinforcement Learning is based on the idea that
agents need to ’reinforced’ to get them to achieve a specific
goal. However, humans and animals have generalist learned
representations of the world, over which they can plan to reach
any desired goal. Recently, LLMs have popularised this paradigm
of learning a general representation with data that can be used
in any required goal easily. In this work, I come up with a way
to perform state abstraction of any general MDP environment
using episodic state transition data, learn useful ’landmarks’ in
the environment, and use these landmarks to deterministically
plan a path to a desired goal. This is the only work as far
as I am aware that uses deterministic planning using ’learned’
landmarks in a general MDP.

Index Terms—NeuroSymbolic methods, Deterministic Planning, Self-Supervised Learning, Markov Decision Process
